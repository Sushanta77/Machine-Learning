{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pjankiewicz/mercari-solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n",
    "\n",
    "from mercari.feature_union import FeatureUnionMP, make_union_mp\n",
    "from mercari.transformers import (\n",
    "    PandasSelector, FastTokenizer,\n",
    "    PreprocessDataPJ, PreprocessDataKL, ConcatTexts, PandasToRecords,\n",
    "    FeaturesEngName, FeaturesEngItemDescription, SparseMatrixOptimize,\n",
    "    FalseBrands, FeaturesPatterns, ExtractSpecifics, SparsityFilter,\n",
    "    NumericalVectorizer, ReportShape, FillEmpty, SGDFeatureSelectionV2,\n",
    "    SanitizeSparseMatrix)\n",
    "\n",
    "\n",
    "def prepare_vectorizer_1(n_jobs=4):\n",
    "    tokenizer = FastTokenizer()\n",
    "    vectorizer = make_pipeline(\n",
    "        PreprocessDataPJ(n_jobs=n_jobs),\n",
    "        make_union_mp(\n",
    "\n",
    "            make_pipeline(\n",
    "                PandasSelector(columns=['name', 'item_description']),\n",
    "                ConcatTexts(columns=['name', 'item_description'],\n",
    "                            use_separators=True),\n",
    "                PandasSelector(columns=['text_concat']),\n",
    "                CountVectorizer(ngram_range=(1, 1), binary=True, min_df=5, tokenizer=tokenizer, dtype=np.float32)\n",
    "            ),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['desc_clean']),\n",
    "                          CountVectorizer(tokenizer=tokenizer,\n",
    "                                          binary=True,\n",
    "                                          min_df=5,\n",
    "                                          ngram_range=(1, 1),\n",
    "                                          dtype=np.float32)),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['name_clean']),\n",
    "                          CountVectorizer(binary=True,\n",
    "                                          analyzer='char_wb',\n",
    "                                          min_df=25,\n",
    "                                          ngram_range=(3, 3),\n",
    "                                          dtype=np.float32)),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['name_clean']),\n",
    "                          CountVectorizer(tokenizer=tokenizer,\n",
    "                                          binary=True,\n",
    "                                          min_df=5,\n",
    "                                          ngram_range=(1, 1),\n",
    "                                          dtype=np.float32),\n",
    "                          SparseMatrixOptimize()),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['category_name_clean']),\n",
    "                          CountVectorizer(tokenizer=tokenizer,\n",
    "                                          binary=True,\n",
    "                                          min_df=5,\n",
    "                                          dtype=np.float32)),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['shipping', 'item_condition_id', 'brand_name_clean',\n",
    "                                                  'cat_1', 'cat_2', 'cat_3', 'no_cat']),\n",
    "                          PandasToRecords(),\n",
    "                          DictVectorizer(dtype=np.float32)),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['name_clean'], return_vector=False),\n",
    "                          FeaturesEngName(),\n",
    "                          MinMaxScaler()),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['desc_clean'], return_vector=False),\n",
    "                          FeaturesEngItemDescription(),\n",
    "                          MinMaxScaler()),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['brand_name', 'item_description']),\n",
    "                          FalseBrands()),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['item_description'], return_vector=False),\n",
    "                          FeaturesPatterns(column='item_description')),\n",
    "\n",
    "            make_pipeline(PandasSelector(columns=['name'], return_vector=False),\n",
    "                          FeaturesPatterns(column='name')),\n",
    "\n",
    "            make_pipeline(\n",
    "                PandasSelector(\"item_description\", return_vector=True),\n",
    "                ExtractSpecifics(),\n",
    "                DictVectorizer(),\n",
    "                SparsityFilter(25),\n",
    "                MaxAbsScaler()\n",
    "            ),\n",
    "\n",
    "            n_jobs=n_jobs\n",
    "        ),\n",
    "        SparseMatrixOptimize(),\n",
    "        SanitizeSparseMatrix(),\n",
    "        ReportShape()\n",
    "    )\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def prepare_vectorizer_2(n_jobs=4):\n",
    "    TOKEN_PATTERN = (\n",
    "            r'(?u)('\n",
    "            r'\"|'  # for inches\n",
    "            r'\\&|'  # & (e.g. in H&M)\n",
    "            r'!+|'  # !\n",
    "            r'\\.\\d+\\b|'  # .25\n",
    "            r'\\b\\d+\\/\\d+\\b|'  # 1/2\n",
    "            r'\\b\\d+\\.?\\d*\\%|'  # 100.1%\n",
    "            r'\\b\\d+\\.?\\d*\\b|'  # 0.25\n",
    "            r'[\\:\\;\\%][\\)\\(]|'  # TODO more smilies\n",
    "            r'[' + ''.join([\n",
    "        '•', '❤', '✨', '$', '❌', '♡', '☆', '✔', '⭐',\n",
    "        '✅', '⚡', '‼', '—', '▪', '❗', '■', '●', '➡',\n",
    "        '⛔', '♦', '〰', '×', '⚠', '°', '♥', '★', '®', '·', '☺', '–', '➖',\n",
    "        '✴', '❣', '⚫', '✳', '➕', '™', 'ᴇ', '》', '✖', '▫', '¤',\n",
    "        '⬆', '⃣', 'ᴀ', '❇', 'ᴏ', '《', '☞', '❄', '»', 'ô', '❎', 'ɴ', '⭕', 'ᴛ',\n",
    "        '◇', 'ɪ', '½', 'ʀ', '❥', '⚜', '⋆', '⏺', '❕', 'ꕥ', '：', '◆', '✽',\n",
    "        '…', '☑', '︎', '═', '▶', '⬇', 'ʟ', '！', '✈', '�', '☀', 'ғ',\n",
    "    ]) + ']|'  # various symbols\n",
    "         r'\\b\\w+\\b'  # word\n",
    "         r')')\n",
    "\n",
    "    # TODO - check gain, maybe remove them?\n",
    "    REPL_PATTERNS = [\n",
    "        (r'\\b(\\d+)([a-z]+)\\b', r'\\1 \\2'),  # 16gb -> 16 gb\n",
    "        (r'\\b([a-z]+)(\\d+)\\b', r'\\1 \\2'),  # gtx780 -> gtx 780\n",
    "        (r'!!+', r'!!'),  # !!!! -> !!\n",
    "    ]\n",
    "\n",
    "    max_feat_descr = 100000\n",
    "    max_feat_name = 100000\n",
    "    num_brands = 2500\n",
    "\n",
    "    vectorizer = make_pipeline(\n",
    "        PreprocessDataKL(num_brands=num_brands, repl_patterns=REPL_PATTERNS),\n",
    "        FeatureUnionMP([\n",
    "\n",
    "            ('descr_idf', make_pipeline(\n",
    "                PandasSelector(columns=['name', 'item_description', 'category_name']),\n",
    "                ConcatTexts(columns=['name', 'item_description', 'category_name'],\n",
    "                            use_separators=True),\n",
    "                PandasSelector(columns=['text_concat']),\n",
    "                TfidfVectorizer(\n",
    "                    max_features=max_feat_descr,\n",
    "                    ngram_range=(1, 2),\n",
    "                    token_pattern=TOKEN_PATTERN,\n",
    "                    dtype=np.float32,\n",
    "                )\n",
    "            )),\n",
    "\n",
    "            ('name_idf',\n",
    "             make_pipeline(\n",
    "                 PandasSelector(columns=['name', 'brand_name']),\n",
    "                 ConcatTexts(columns=['name', 'brand_name'],\n",
    "                             use_separators=True),\n",
    "                 PandasSelector(columns=['text_concat']),\n",
    "                 CountVectorizer(\n",
    "                     max_features=max_feat_name,\n",
    "                     ngram_range=(1, 2),\n",
    "                     token_pattern=TOKEN_PATTERN,\n",
    "                     dtype=np.float32,\n",
    "                 ))),\n",
    "\n",
    "            ('num_vect_name', make_pipeline(\n",
    "                PandasSelector(columns=['name', 'item_description']),\n",
    "                ConcatTexts(columns=['name', 'item_description'],\n",
    "                            use_separators=True),\n",
    "                PandasSelector(columns=['text_concat']),\n",
    "                NumericalVectorizer(token_pattern=TOKEN_PATTERN,\n",
    "                                    min_df=5,\n",
    "                                    stop_words=\"english\",\n",
    "                                    ngram_range=(1, 1)))),\n",
    "\n",
    "            ('category_idf',\n",
    "             make_pipeline(PandasSelector('category_name'),\n",
    "                           CountVectorizer(dtype=np.float32))),\n",
    "\n",
    "            ('ohe', make_pipeline(\n",
    "                PandasSelector(columns=['shipping', 'no_description',\n",
    "                                        'item_condition_id', 'brand_name',\n",
    "                                        'category_name_l2', 'category_name']),\n",
    "                PandasToRecords(),\n",
    "                DictVectorizer(),\n",
    "            )),\n",
    "        ], n_jobs=n_jobs),\n",
    "        SparseMatrixOptimize(),\n",
    "        SanitizeSparseMatrix(),\n",
    "        ReportShape()\n",
    "    )\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def prepare_vectorizer_3(n_jobs=4):\n",
    "    token_pattern = r\"(?u)\\b\\w+\\b\"\n",
    "    vectorizer = make_pipeline(\n",
    "        PreprocessDataPJ(n_jobs=n_jobs),\n",
    "        FillEmpty(),\n",
    "        FeatureUnionMP([\n",
    "\n",
    "            ('tf_idf_1g', make_pipeline(\n",
    "                PandasSelector(columns=['name_clean', 'brand_name_clean', 'category_name', 'desc_clean']),\n",
    "                ConcatTexts(columns=['name_clean', 'brand_name_clean', 'category_name', 'desc_clean'],\n",
    "                            use_separators=True),\n",
    "                PandasSelector(columns=['text_concat']),\n",
    "                TfidfVectorizer(ngram_range=(1, 1), binary=True, min_df=5, token_pattern=token_pattern)\n",
    "            )),\n",
    "\n",
    "            ('tf_idf_2g', make_pipeline(\n",
    "                PandasSelector(columns=['name_clean', 'brand_name_clean', 'category_name', 'desc_clean']),\n",
    "                ConcatTexts(columns=['name_clean', 'brand_name_clean', 'category_name', 'desc_clean'],\n",
    "                            use_separators=True),\n",
    "                PandasSelector(columns=['text_concat']),\n",
    "                TfidfVectorizer(ngram_range=(2, 2), binary=True, min_df=5, token_pattern=token_pattern),\n",
    "                SGDFeatureSelectionV2(70),\n",
    "                ReportShape()\n",
    "            )),\n",
    "\n",
    "            ('name_chargrams', make_pipeline(\n",
    "                PandasSelector('name'),\n",
    "                TfidfVectorizer(ngram_range=(3, 3), analyzer='char', binary=True, min_df=25),\n",
    "            )),\n",
    "\n",
    "            ('ohe', make_pipeline(\n",
    "                PandasSelector(columns=['shipping',\n",
    "                                        'item_condition_id', 'brand_name',\n",
    "                                        'cat_1', 'cat_2', 'cat_3', 'no_cat']),\n",
    "                PandasToRecords(),\n",
    "                DictVectorizer()\n",
    "            )),\n",
    "\n",
    "            ('is_name', make_pipeline(\n",
    "                PandasSelector(\"name\", return_vector=True),\n",
    "                ExtractSpecifics(),\n",
    "                DictVectorizer(),\n",
    "                SparsityFilter(25),\n",
    "                MaxAbsScaler()\n",
    "            ))\n",
    "        ], n_jobs=n_jobs),\n",
    "        SparseMatrixOptimize(),\n",
    "        SanitizeSparseMatrix(),\n",
    "        ReportShape()\n",
    "    )\n",
    "    return vectorizer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
